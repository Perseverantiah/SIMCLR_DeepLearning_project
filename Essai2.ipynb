{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7ad6fb-2859-457b-b8f2-de7c1ad5322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Charger le dataset complet\n",
    "full_trainset = datasets.MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "# Indices pour chaque classe\n",
    "class_indices = {i: [] for i in range(10)}\n",
    "for idx, (_, label) in enumerate(full_trainset):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "# Sélectionner 10 indices par classe pour les données labellisées\n",
    "labeled_indices = []\n",
    "for cls in range(10):\n",
    "    labeled_indices.extend(random.sample(class_indices[cls], 10))\n",
    "\n",
    "# Indices restants pour les données non labellisées\n",
    "unlabeled_indices = list(set(range(len(full_trainset))) - set(labeled_indices))\n",
    "\n",
    "# Sous-ensembles\n",
    "unlabeled_dataset = Subset(full_trainset, unlabeled_indices)  # 59 900 données non labellisées\n",
    "labeled_dataset = Subset(full_trainset, labeled_indices)      # 100 données labellisées\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Analyse de la répartition des classes dans les données labellisées\n",
    "class_count_labelled = {}\n",
    "for i in range(len(labeled_indices)):\n",
    "    label = full_trainset.targets[labeled_indices[i]].item()  # Récupérer les labels des indices labellisés\n",
    "    if label not in class_count_labelled:\n",
    "        class_count_labelled[label] = 0\n",
    "    class_count_labelled[label] += 1\n",
    "\n",
    "# Création d'un DataFrame pour faciliter la visualisation\n",
    "df_labelled = pd.DataFrame(class_count_labelled.items(), columns=[\"Label\", \"Occurrence\"])\n",
    "df_labelled[\"Occurrence (%)\"] = (df_labelled[\"Occurrence\"] / len(labeled_indices)) * 100\n",
    "\n",
    "# Visualisation avec Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(x=\"Label\", y=\"Occurrence (%)\", data=df_labelled, color=\"green\")\n",
    "plt.title(\"Répartition des classes dans les données labellisées\")\n",
    "plt.xlabel(\"Classe\")\n",
    "plt.ylabel(\"Pourcentage d'occurrences (%)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851c55c-ca1e-4b69-8fd2-100a1ae6220a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff91449-fb37-4608-a965-b8eb466b039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de : cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Vérifier si un GPU est disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Utilisation de :\", device)\n",
    "\n",
    "\n",
    "\n",
    "contrastive_transforms = transforms.Compose([\n",
    "\n",
    "    transforms.RandomResizedCrop(size=28, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=9),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "class SimCLRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.dataset[idx]  # Ignorer les labels pour le pré-entraînement\n",
    "        img1 = self.transform(img)\n",
    "        img2 = self.transform(img)\n",
    "        return img1, img2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "# Dataset avec transformations contrastives\n",
    "simclr_unlabeled_dataset = SimCLRDataset(unlabeled_dataset, contrastive_transforms)\n",
    "unlabeled_loader = DataLoader(simclr_unlabeled_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Backbone CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "# Tête de projection\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Combinaison Backbone + Projection Head\n",
    "cnn = SimpleCNN()\n",
    "projection_head = ProjectionHead(input_dim=3136, output_dim=128)  # Adapter input_dim si nécessaire\n",
    "simclr_model = nn.Sequential(cnn, projection_head).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_loss(projections1, projections2, temperature=0.07):\n",
    "    z1 = F.normalize(projections1, dim=1)\n",
    "    z2 = F.normalize(projections2, dim=1)\n",
    "    similarity_matrix = torch.matmul(z1, z2.T) / temperature\n",
    "    batch_size = z1.size(0)\n",
    "    labels = torch.arange(batch_size).to(z1.device)\n",
    "    loss1 = F.cross_entropy(similarity_matrix, labels)\n",
    "    loss2 = F.cross_entropy(similarity_matrix.T, labels)\n",
    "    return (loss1 + loss2) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93cb44b-431a-45c7-9ab9-a1146f6a9ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.7557378467331586\n",
      "Epoch 2/10, Loss: 0.8578567410636152\n",
      "Epoch 3/10, Loss: 0.6877784471735995\n",
      "Epoch 4/10, Loss: 0.5936208301120334\n",
      "Epoch 5/10, Loss: 0.528209313750267\n",
      "Epoch 6/10, Loss: 0.49893631996252596\n",
      "Epoch 7/10, Loss: 0.46051965730312544\n",
      "Epoch 8/10, Loss: 0.4365367317556316\n",
      "Epoch 9/10, Loss: 0.4216135058902268\n",
      "Epoch 10/10, Loss: 0.404738251470093\n"
     ]
    }
   ],
   "source": [
    "# Pre-entrainement\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Optimiseur\n",
    "optimizer = optim.Adam(simclr_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "simclr_model.train()\n",
    "epochs = 10  # Ajuster le nombre d'époques selon vos besoins\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for (view1, view2) in unlabeled_loader:\n",
    "        view1, view2 = view1.to(device), view2.to(device)\n",
    "\n",
    "        # Projections\n",
    "        projections1 = simclr_model(view1)\n",
    "        projections2 = simclr_model(view2)\n",
    "\n",
    "        # Calcul de la perte\n",
    "        loss = contrastive_loss(projections1, projections2)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(unlabeled_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07857e-6552-47e4-927c-1a85ad8cb309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e926e-d077-4069-a458-0800904e4aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8f77f-42ab-42d9-8b68-9465fe5932d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca26c432-7d32-48c9-8300-ebc91e0246a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressive_fine_tuning(pretrained_model, labeled_dataset, val_dataset, num_classes=10, max_labels=100, step=10, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Effectue un fine-tuning progressif sur un modèle préentraîné.\n",
    "    \n",
    "    Args:\n",
    "        pretrained_model: Modèle préentraîné à fine-tuner.\n",
    "        labeled_dataset: Dataset contenant les données labellisées.\n",
    "        val_dataset: Dataset de validation pour évaluer les performances.\n",
    "        num_classes: Nombre de classes dans le dataset.\n",
    "        max_labels: Nombre total de données labellisées disponibles.\n",
    "        step: Taille de l'incrément des données labellisées.\n",
    "        device: \"cpu\" ou \"cuda\" pour entraîner sur GPU.\n",
    "    \n",
    "    Returns:\n",
    "        history: Un dictionnaire contenant la loss et l'accuracy pour chaque étape.\n",
    "    \"\"\"\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import DataLoader, Subset\n",
    "    import numpy as np\n",
    "\n",
    "    # Historique des performances\n",
    "    history = {\"num_labels\": [], \"accuracy\": [], \"loss\": []}\n",
    "\n",
    "    # Boucle sur les tailles croissantes de données labellisées\n",
    "    for num_labels in range(step, max_labels + 1, step):\n",
    "        print(f\"\\nFine-tuning avec {num_labels} données labellisées...\")\n",
    "\n",
    "        # Sous-échantillonnage du dataset labellisé\n",
    "        indices = np.random.choice(len(labeled_dataset), num_labels, replace=False)\n",
    "        subset = Subset(labeled_dataset, indices)\n",
    "        train_loader = DataLoader(subset, batch_size=32, shuffle=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Modèle pour fine-tuning\n",
    "        model = nn.Sequential(\n",
    "            pretrained_model,\n",
    "            nn.Linear(128, num_classes)  # Tête de classification\n",
    "        ).to(device)\n",
    "\n",
    "        # Optimiseur et fonction de perte\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Entraînement\n",
    "        model.train()\n",
    "        for epoch in range(5):  # 5 époques pour chaque étape\n",
    "            for inputs, labels in train_loader:\n",
    "                if isinstance(inputs, (list, tuple)):  # Gérer les vues augmentées si présentes\n",
    "                    inputs = inputs[0]\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Évaluation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                if isinstance(inputs, (list, tuple)):  # Cas où les inputs contiennent plusieurs vues\n",
    "                    inputs = inputs[0]  # Utilisez la première vue pour l'évaluation\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        avg_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Stockage des performances\n",
    "        history[\"num_labels\"].append(num_labels)\n",
    "        history[\"accuracy\"].append(accuracy)\n",
    "        history[\"loss\"].append(avg_loss)\n",
    "        print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3011ca0-97b3-45ce-a07c-326143b35a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning avec 10 données labellisées...\n",
      "Validation Loss: 2.3153, Accuracy: 0.0767\n",
      "\n",
      "Fine-tuning avec 20 données labellisées...\n",
      "Validation Loss: 2.3092, Accuracy: 0.0952\n",
      "\n",
      "Fine-tuning avec 30 données labellisées...\n",
      "Validation Loss: 2.3075, Accuracy: 0.0960\n",
      "\n",
      "Fine-tuning avec 40 données labellisées...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fine-tuning progressif\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m progressive_fine_tuning(\n\u001b[0;32m      3\u001b[0m     pretrained_model\u001b[38;5;241m=\u001b[39msimclr_model,\n\u001b[0;32m      4\u001b[0m     labeled_dataset\u001b[38;5;241m=\u001b[39mlabeled_dataset,\n\u001b[0;32m      5\u001b[0m     val_dataset\u001b[38;5;241m=\u001b[39mvalset,\n\u001b[0;32m      6\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      7\u001b[0m     max_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      8\u001b[0m     step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      9\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Plot des résultats\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[29], line 47\u001b[0m, in \u001b[0;36mprogressive_fine_tuning\u001b[1;34m(pretrained_model, labeled_dataset, val_dataset, num_classes, max_labels, step, device)\u001b[0m\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):  \u001b[38;5;66;03m# 5 époques pour chaque étape\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):  \u001b[38;5;66;03m# Gérer les vues augmentées si présentes\u001b[39;00m\n\u001b[0;32m     49\u001b[0m             inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[38;5;241m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:240\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    236\u001b[0m                 collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    237\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    238\u001b[0m             ]\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "# Fine-tuning progressif\n",
    "history = progressive_fine_tuning(\n",
    "    pretrained_model=simclr_model,\n",
    "    labeled_dataset=labeled_dataset,\n",
    "    val_dataset=valset,\n",
    "    num_classes=10,\n",
    "    max_labels=100,\n",
    "    step=10,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Plot des résultats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history[\"num_labels\"], history[\"accuracy\"], marker=\"o\", label=\"Accuracy\")\n",
    "plt.xlabel(\"Nombre de données étiquetées\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy en fonction des données étiquetées\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history[\"num_labels\"], history[\"loss\"], marker=\"o\", color=\"red\", label=\"Loss\")\n",
    "plt.xlabel(\"Nombre de données étiquetées\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss en fonction des données étiquetées\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a85a1-f68f-4596-9d0f-4c5fc27b77e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162191d-926e-4546-8ace-3a69fc838fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a244495-a045-4bca-adaa-d6f3d7aa4dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "862d5b32-ea12-4a70-97af-dfc76b0d9819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressive_fine_tuning(pretrained_model, labeled_dataset, val_dataset, num_classes=10, max_labels=100, step=10, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Effectue un fine-tuning progressif sur un modèle préentraîné.\n",
    "    \n",
    "    Args:\n",
    "        pretrained_model: Modèle préentraîné à fine-tuner.\n",
    "        labeled_dataset: Dataset contenant les données labellisées.\n",
    "        val_dataset: Dataset de validation pour évaluer les performances.\n",
    "        num_classes: Nombre de classes dans le dataset.\n",
    "        max_labels: Nombre total de données labellisées disponibles.\n",
    "        step: Taille de l'incrément des données labellisées.\n",
    "        device: \"cpu\" ou \"cuda\" pour entraîner sur GPU.\n",
    "    \n",
    "    Returns:\n",
    "        history: Un dictionnaire contenant la loss et l'accuracy pour chaque étape.\n",
    "    \"\"\"\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import DataLoader, Subset\n",
    "    import numpy as np\n",
    "\n",
    "    # Historique des performances\n",
    "    history = {\"num_labels\": [], \"accuracy\": [], \"loss\": []}\n",
    "\n",
    "    # Boucle sur les tailles croissantes de données labellisées\n",
    "    for num_labels in range(step, max_labels + 1, step):\n",
    "        print(f\"\\nFine-tuning avec {num_labels} données labellisées...\")\n",
    "\n",
    "        # Sous-échantillonnage du dataset labellisé\n",
    "        indices = np.random.choice(len(labeled_dataset), num_labels, replace=False)\n",
    "        subset = Subset(labeled_dataset, indices)\n",
    "        \n",
    "        # Réduction de la taille du batch pour correspondre au nombre de données\n",
    "        batch_size = min(num_labels, 32)  # Si moins de données que le batch_size, on réduit\n",
    "        train_loader = DataLoader(subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Modèle pour fine-tuning\n",
    "        model = nn.Sequential(\n",
    "            pretrained_model,\n",
    "            nn.Linear(128, num_classes)  # Tête de classification\n",
    "        ).to(device)\n",
    "\n",
    "        # Optimiseur et fonction de perte\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Entraînement\n",
    "        model.train()\n",
    "        for epoch in range(5):  # 5 époques pour chaque étape\n",
    "            for inputs, labels in train_loader:\n",
    "                if isinstance(inputs, (list, tuple)):  # Gérer les vues augmentées si présentes\n",
    "                    inputs = inputs[0]\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Évaluation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                if isinstance(inputs, (list, tuple)):  # Cas où les inputs contiennent plusieurs vues\n",
    "                    inputs = inputs[0]  # Utilisez la première vue pour l'évaluation\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        avg_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Stockage des performances\n",
    "        history[\"num_labels\"].append(num_labels)\n",
    "        history[\"accuracy\"].append(accuracy)\n",
    "        history[\"loss\"].append(avg_loss)\n",
    "        print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b728a-2bdc-4144-8ffe-6cc7350b34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning progressif\n",
    "history = progressive_fine_tuning(\n",
    "    pretrained_model=simclr_model,\n",
    "    labeled_dataset=labeled_dataset,\n",
    "    val_dataset=valset,\n",
    "    num_classes=10,\n",
    "    max_labels=100,\n",
    "    step=10,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Plot des résultats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history[\"num_labels\"], history[\"accuracy\"], marker=\"o\", label=\"Accuracy\")\n",
    "plt.xlabel(\"Nombre de données étiquetées\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy en fonction des données étiquetées\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history[\"num_labels\"], history[\"loss\"], marker=\"o\", color=\"red\", label=\"Loss\")\n",
    "plt.xlabel(\"Nombre de données étiquetées\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss en fonction des données étiquetées\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bd0cb4a-f0d7-40bf-b108-5273cb0b75ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longueur du dataset labellisé : 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Longueur du dataset labellisé : {len(labeled_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb77ab6-790c-4f6b-9cb2-099a24e580a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
